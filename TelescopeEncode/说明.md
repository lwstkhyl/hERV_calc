**配置环境**：
```sh
conda create -n telescope -c conda-forge -c bioconda \
  python=3.10 telescope bowtie2 samtools sra-tools parallel-fastq-dump \
  flexbar bedtools entrez-direct pigz -y
```
**下载ENCODE数据**：以SRP014320为例
```sh
# 列出 SRP014320 的全部 Run，并保存 CSV
esearch -db sra -query SRP014320 | efetch -format runinfo > SRP014320_runinfo.csv
# 以 H1-hESC 为例筛选
grep -i 'H1' SRP014320_runinfo.csv > H1_runinfo.csv
# 提取 SRR 列成清单
awk -F, 'NR>1 {print $1}' H1_runinfo.csv > SRR_H1.txt
```
为了节省磁盘空间，只取`SRR_H1.txt`的前两个数据`SRR521515`和`SRR521514`
```sh
# 并行下载并直接生成FASTQ
parallel-fastq-dump --sra-id $(head -n1 SRR_H1.txt) --threads 8 --split-files --outdir fastq
# 质控/剪接
flexbar -r fastq/$(head -n1 SRR_H1.txt)_1.fastq -p fastq/$(head -n1 SRR_H1.txt)_2.fastq \
        -t fastq/$(head -n1 SRR_H1.txt)_trim --adapter-trim-end RIGHT --min-read-length 30
```
- 生成一个fastq文件夹，主要包含4个文件，格式为`SRR521514_trim_1.fastq`和`SRR521514_trim_2.fastq`

注：这里`$(head -n1 SRR_H1.txt)`是取txt里的第一行样本，没有设置循环，需要手动执行两次（下面类似）

**下载人类参考基因组hg38**：
```sh
mkdir refs && cd refs
wget https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/latest/hg38.fa.gz
gunzip hg38.fa.gz
bowtie2-build hg38.fa hg38
cd ..
```
- 生成的refs文件夹即为hg38参考基因组

**下载HERV注释**：直接用作者提供的HERV_rmsk.hg38.v2/genes.gtf
```sh
# 需要先下载git lfs
sudo apt-get install git-lfs
git lfs install
git clone https://github.com/mlbendall/telescope_annotation_db
# 根据人类参考基因组版本选择注释文件路径
ANN=./telescope_annotation_db/builds/HERV_rmsk.hg38.v2/genes.gtf
```
**比对到基因组**：使用论文参数运行时发现时间非常长，于是调整参数
```sh
SRR="SRR521515"
bowtie2 -x refs/hg38 -1 fastq/${SRR}_trim_1.fastq -2 fastq/${SRR}_trim_2.fastq \
  # --very-sensitive-local -k 100 --score-min L,0,1.6 -p 8 \  # 论文参数
  --sensitive-local -k 20 --score-min L,0,1.6 -p 8 \  # 为节省时间调整后参数
  2> ${SRR}.bowtie2.log | samtools view -bS - | samtools sort -o ${SRR}.sorted.bam
SRR="SRR521514"
bowtie2 -x refs/hg38 -1 fastq/${SRR}_trim_1.fastq -2 fastq/${SRR}_trim_2.fastq \
  # --very-sensitive-local -k 100 --score-min L,0,1.6 -p 8 \  # 论文参数
  --sensitive-local -k 20 --score-min L,0,1.6 -p 8 \  # 为节省时间调整后参数
  2> ${SRR}.bowtie2.log | samtools view -bS - | samtools sort -o ${SRR}.sorted.bam
```
- 生成`SRR521515.sorted.bam`和`SRR521514.sorted.bam`

观察这两个样本是否为同一个H1样本的技术重复：
```sh
# 分别拉取 runinfo（CSV），看关键列是否一致
esearch -db sra -query SRR521514 | efetch -format runinfo > SRR521514.csv
esearch -db sra -query SRR521515 | efetch -format runinfo > SRR521515.csv
```
查询`SRR521514.csv`和`SRR521515.csv`
- 同一Experiment且同一BioSample：同一文库被多次上机，是技术重复，可合并作为一个样本来运行后续步骤
- Experiment不同但BioSample相同：同一生物样本做了不同文库；通常也按技术重复处理，但合并前要确认LibraryStrategy/Layout/读长/建库是否一致
- BioSample不同：不是同一样本（一般是生物学重复），不要合并

这里发现Experiment和BioSample都相同，因此运行下面的合并命令
```sh
samtools merge H1_sample.merged.bam SRR521515.sorted.bam SRR521514.sorted.bam -@ 8
```
- 生成`merge H1_sample.merged.bam`——整合后的bam文件

**telescope**：需要输入的BAM文件不能是坐标排序，必须`samtools sort -n`或`samtools collate`
```sh
samtools sort -o H1_sample.merged.sorted.bam H1_sample.merged.bam -@ 8
samtools index H1_sample.merged.sorted.bam
samtools collate -@ 8 -o H1_sample.collate.bam H1_sample.merged.sorted.bam
```
- 最后生成`H1_sample.collate.bam`——排序后的比对结果

先检查telescope是否能正常运行
```sh
eval $(telescope test)
```
- 正常会生成一个`telescope-telescope_report.tsv`，我这里报错`AttributeError: module 'numpy' has no attribute 'int'.`，查询GitHub issue后发现是作者的源码有问题。把`/home/userName/miniconda3/envs/telescope_env/lib/python3.10/site-packages/telescope/utils/model.py`里面的`np.int`改成`int`即可

```sh
mkdir telescope_out
telescope assign H1_sample.collate.bam ${ANN} \
  --outdir telescope_out --exp_tag H1_sample \
  --theta_prior 200000 --max_iter 200
```
![telescope_res](/upload/md-image/other/telescope_res.png){:width="800px" height="800px"}
